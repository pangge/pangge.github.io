<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[goldencui]]></title>
  <subtitle><![CDATA[get a real life]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://goldencui.org/"/>
  <updated>2014-12-06T03:02:42.273Z</updated>
  <id>http://goldencui.org/</id>
  
  <author>
    <name><![CDATA[goldencwcui]]></name>
    <email><![CDATA[goldencwcui@hotmail.com]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[简明深度学习方法概述（二）]]></title>
    <link href="http://goldencui.org/2014/12/06/%E7%AE%80%E6%98%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://goldencui.org/2014/12/06/简明深度学习方法概述（二）/</id>
    <published>2014-12-06T02:00:08.000Z</published>
    <updated>2014-12-06T02:24:06.000Z</updated>
    <content type="html"><![CDATA[<p> <img src="/imgs/nn2.jpg" alt=""></p>
<h1 id="三类深度学习网络"><strong>三类深度学习网络</strong></h1>
<p>本篇介绍深度学习的大致分类，根据其应用方式的不同，我们可以粗分类几种不同结构的深度学习方法。</p>
<h2 id="(1)_三种深度学习网络分类方式">(1)   三种深度学习网络分类方式</h2>
<p><a id="more"></a><br>如文章（一）中所述，深度网络是指一大类的机器学习和各种层次结构结合的网络，其特性是使用多层的非线性信息处理方法（这和一般神经网络结构类似，包含了更多的隐层）。根据这些结构和技术的应用领域比如综合/生成或识别/分类，我们可以大致的把这些结构分为三类：</p>
<ol>
<li><strong>非监督学习或生成学习深度网络</strong>，当目标的类标签信息不可获取的时候，这类深度网络趋向于为了模式分析和综合的目的，提取可视数据中高度自相关性（可参考机器学习中对于非监督学习的描述）。在学术上，非监督特征或者表示学习指的就是这类深度网络。当用在生成模型中的时候，很多这类模型也用来描述可视数据的统计分布和他们的相关类属的分布，并把它们作为数据的一部分。</li>
<li><strong>监督学习深度网络</strong>，这类模型用在直接提供模式分类中的识别能力，经常以描述可视数据的类的后验分布形式给出。类标签可以直接或间接得到（因为是监督学习）。</li>
<li><strong>混合深度网络</strong>，目标是辅加生成学习或者深度非监督学习效果的数据分类问题。一般可以使用最优化和第2类深度网络模型来解决。这种网络使用监督学习的标准去估计任何深度生成模型或者非监督深度网络中的参数。</li>
</ol>
<p>“混合”这一称呼和一般学术指的不同，学术上可能指把一个神经网络的概率输出反馈到HMM（隐形马尔科夫模型，推荐李航的《统计学习方法》中了解）中所组成的语音识别系统。<br>如果按照普通的采用机器学习的惯例，那就可以很自然的把深度学习技术分为深度判别模型（监督学习）（比如深度神经网络或者DNNS，递归神经网络或者RNNs，卷积神经网络或者CNNs等等）和生成或非监督模型（比如限制玻尔兹曼机或者RBMs，深信网络或者DBNs，深度玻尔兹曼机（DBMs）规则自编码器等等）。但这两种分类方式都忽略了生成或非监督模型通过最优化和正则化可以极大的改进DNNs和其他深度判定模型和监督模型的训练。并且，深度无监督学习网络未必能从数据中有意义的采样。我们注意到已经有研究通过生成传统的去噪自编码器来来有效采样（具体论文不列出，大家可以去搜搜看）。不管怎么说，传统的两种分类方式的确指出了监督学习和非监督学习深度网络中的不同点。比较上面提到的两类深度学习方法，深度监督学习方法例如DNNs是通常可以有效测试和训练的模型，可以灵活构建并且适合复杂系统的首位相连的学习（比如loopy belief propagation）。另一方面来说，深度非监督学习模型，特别是概率生成模型，更容易解释，容易嵌入局部先验知识，容易组织和容易处理不确定性。但是它在推理学习和复杂系统学习方面比较困难。这些区分也保留在本文推荐的三类深度网络模型分类里面，这是一个好现象。</p>
<h2 id="(2)_非监督学习或生成学习深度网络">(2)      非监督学习或生成学习深度网络</h2>
<p>非监督学习指学习没有监督信息的数据（比如根本没有数据的类标签，无法根据数据的类属性分类）。很多这类深度网络可以从神经网络知识里借鉴生成，比如RBMs，DBNs，DBMs和生成去噪自编码器。还有一些比如稀疏编码网络以及深度自编码器的原始形式。下面给出这类网络的样例以及相关文献信息，具体内容可以根据兴趣学习：</p>
<p><em>[1]    Y. Bengio, N. Boulanger, and R. Pascanu. Advances in optimizing recurrent networks. In Proceedings of International Conference on Acoustics Speech and Signal Processing (ICASSP). 2013<br>[2]    Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layerwise training of deep networks. In Proceedings of Neural Information Processing Systems (NIPS). 2006.<br>[3]    Y. Bengio. Learning deep architectures for AI. in Foundations and Trends in Machine Learning, 2(1):1–127, 2009.<br>[4]    Y. LeCun, S. Chopra, M. Ranzato, and F. Huang. Energy-based models in document recognition and computer vision. In Proceedings of International Conference on Document Analysis and Recognition (ICDAR).2007.<br>[5]    J. Ngiam, Z. Chen, P. Koh, and A. Ng. Learning deep energy models. In Proceedings of International Conference on Machine Learning (ICML).2011.<br>[6]    L. Deng, M. Seltzer, D. Yu, A. Acero, A. Mohamed, and G. Hinton.Binary coding of speech spectrograms using a deep autoencoder. In Proceedings of Interspeech. 2010.<br>[7]    G. Hinton and R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507, July 2006.<br>[8]    P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P. Manzagol.Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Journal of Machine Learning Research, 11:3371–3408, 2010.<br>[9]    G. Hinton. A better way to learn features. Communications of the Association for Computing Machinery (ACM), 54(10), October 2011.<br>[10]    I. Goodfellow, M. Mirza, A. Courville, and Y. Bengio. Multi-prediction deep boltzmann machines. In Proceedings of Neural Information Processing Systems (NIPS). 2013.<br>[11]    R. Salakhutdinov and G. Hinton. Deep boltzmann machines. In Proceedings of Artificial Intelligence and Statistics (AISTATS). 2009.<br>[12]    R. Salakhutdinov and G. Hinton. A better way to pretrain deep Boltzmann machines. In Proceedings of Neural Information Processing Systems (NIPS). 2012.<br>[13]    N. Srivastava and R. Salakhutdinov. Multimodal learning with deep boltzmann machines. In Proceedings of Neural Information Processing Systems (NIPS). 2012.<br>[14]    G. Dahl, M. Ranzato, A. Mohamed, and G. Hinton. Phone recognition with the mean-covariance restricted boltzmann machine. In Proceedings of Neural Information Processing Systems (NIPS), volume 23, pages 469–477. 2010.<br>[15]    M. Ranzato and G. Hinton. Modeling pixel means and covariances using factorized third-order boltzmann machines. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2010.<br>[16]    A. Mohamed, G. Hinton, and G. Penn. Understanding how deep belief networks perform acoustic modelling. In Proceedings of International Conference on Acoustics Speech and Signal Processing (ICASSP). 2012.<br>[17]    R. Gens and P. Domingo. Discriminative learning of sum-product networks.Neural Information Processing Systems (NIPS), 2012.<br>[18]    H. Poon and P. Domingos. Sum-product networks: A new deep architecture.In Proceedings of Uncertainty in Artificial Intelligence. 2011.<br>[19]    J. Martens and I. Sutskever. Learning recurrent neural networks with hessian-free optimization. In Proceedings of International Conference on Machine Learning (ICML). 2011.<br>[20]    Y. Bengio. Deep learning of representations: Looking forward. In Statistical Language and Speech Processing, pages 1–37. Springer, 2013.<br>[21]    I. Sutskever. Training recurrent neural networks. Ph.D. Thesis, University of Toronto, 2013.<br>[22]    T. Mikolov, M. Karafiat, L. Burget, J. Cernocky, and S. Khudanpur. Recurrent neural network based language model. In Proceedings of International Conference on Acoustics Speech and Signal Processing (ICASSP), pages 1045–1048. 2010.<br>[23]    G. Mesnil, X. He, L. Deng, and Y. Bengio. Investigation of recurrentneural-network architectures and learning methods for spoken language understanding. In Proceedings of Interspeech. 2013.<br>[24]    K. Yao, G. Zweig, M. Hwang, Y. Shi, and D. Yu. Recurrent neural networks for language understanding. In Proceedings of Interspeech.2013.<br>[25]    Z. Ling, L. Deng, and D. Yu. Modeling spectral envelopes using restricted boltzmann machines for statistical parametric speech synthesis.In International Conference on Acoustics Speech and Signal Processing (ICASSP), pages 7825–7829. 2013.<br>[26]    M. Shannon, H. Zen, and W. Byrne. Autoregressive models for statistical parametric speech synthesis. IEEE Transactions on Audio, Speech,Language Processing, 21(3):587–597, 2013.<br>[27]    H. Zen, Y. Nankaku, and K. Tokuda. Continuous stochastic feature mapping based on trajectory HMMs. IEEE Transactions on Audio,Speech, and Language Processings, 19(2):417–430, February 2011.<br>[28]    M. Wohlmayr, M. Stark, and F. Pernkopf. A probabilistic interaction model for multi-pitch tracking with factorial hidden markov model.IEEE Transactions on Audio, Speech, and Language Processing, 19(4),May 2011.<br>[29]    R. Socher, C. Lin, A. Ng, and C. Manning. Parsing natural scenes and natural language with recursive neural networks. In Proceedings of International Conference on Machine Learning (ICML). 2011.<br>[30]    R. Socher, Y. Bengio, and C. Manning. Deep learning for NLP.Tutorial at Association of Computational Logistics (ACL), 2012, and North American Chapter of the Association of Computational Linguistics (NAACL), 2013.<br><a href="http://www.socher.org/index.php/DeepLearning" target="_blank" rel="external">http://www.socher.org/index.php/DeepLearning</a> Tutorial.</em><br>（有点多。。。大家可以根据需要检索，不过都是比较新的索引文献，值得一读）</p>
<h2 id="(3)_监督学习深度网络">(3)      监督学习深度网络</h2>
<p>很多信号和信息处理方面的监督学习的判别技术都是浅层结构比如HMMs（隐形马尔科夫模型）和条件随机场（CRFs），条件随机场本质上就是一个浅层判别模型，在输入特征和多度特征上用线性关系描述。最近深度组织CRFs被提出来，它存储每一层CRF的输出，和原始输入数据一起传输到它的更高层。各种版本的深度组织CRFs已经成功的应用在了电话语音识别，语音识别和自然语言处理上。下面给出监督学习相关的深度网络方面的参考文献，具体内容大家根据兴趣查找阅读：</p>
<p><em>[1]    M. Gibson and T. Hain. Error approximation and minimum phone error acoustic model estimation. IEEE Transactions on Audio, Speech, and Language Processing, 18(6):1269–1279, August 2010.<br>[2]    Heintz, E. Fosler-Lussier, and C. Brew. Discriminative input stream combination for conditional random field phone recognition. IEEE Transactions on Audio, Speech, and Language Processing, 17(8):1533–1546, November 2009.<br>[3]    G. Heigold, H. Ney, P. Lehnen, T. Gass, and R. Schluter. Equivalence of generative and log-liner models. IEEE Transactions on Audio, Speech,and Language Processing, 19(5):1138–1148, February 2011.<br>[4]    D. Yu, S. Wang, and L. Deng. Sequential labeling using deep-structured conditional random fields. Journal of Selected Topics in Signal Processing,4:965–973, 2010.<br>[5]    D. Yu and L. Deng. Deep-structured hidden conditional random fields for phonetic recognition. In Proceedings of Interspeech. September 2010.<br>[6]    D. Yu, S. Wang, and L. Deng. Sequential labeling using deep-structured conditional random fields. Journal of Selected Topics in Signal Processing,4:965–973, 2010.<br>[7]    N. Morgan. Deep and wide: Multiple layers in automatic speech recognition.IEEE Transactions on Audio, Speech, &amp; Language Processing,20(1), January 2012.<br>[8]    L. Deng and D. Yu. Deep convex network: A scalable architecture for speech pattern classification. In Proceedings of Interspeech. 2011<br>[9]    L. Deng, D. Yu, and J. Platt. Scalable stacking and learning for building deep architectures. In Proceedings of International Conference on Acoustics Speech and Signal Processing (ICASSP). 2012a.<br>[10]    B. Hutchinson, L. Deng, and D. Yu. A deep architecture with bilinear modeling of hidden representations: Applications to phonetic recognition.In Proceedings of International Conference on Acoustics Speech and Signal Processing (ICASSP). 2012.<br>[11]    L. Deng, G. Tur, X. He, and D. Hakkani-Tur. Use of kernel deep convex networks and end-to-end learning for spoken language understanding.In Proceedings of IEEE Workshop on Spoken Language Technologies.December 2012.<br>[12]    L. Deng, K. Hassanein, and M. Elmasry. Analysis of correlation structure for a neural predictive model with application to speech recognition.Neural Networks, 7(2):331–339, 1994.<br>[13]    A. Graves. Sequence transduction with recurrent neural networks. Representation<br>[14]    Learning Workshop, International Conference on Machine Learning (ICML), 2012<br>[15]    A. Graves, A. Mohamed, and G. Hinton. Speech recognition with deep recurrent neural networks. In Proceedings of International Conference on Acoustics Speech and Signal Processing (ICASSP). 2013.</em></p>
<h2 id="(4)_混合深度网络">(4)    混合深度网络</h2>
<p>“混合”这个名词使用在这个类别里正是指一类既包含和利用了生成模型也用了判别模型的一种深度网络。在目前学术圈发表的混合结构模型中，生成组件最常被用来帮助判别模型，判别模型是这个混合模型的最终目标。生成模型如何促进判别模型可以从下列两种观点来佐证：</p>
<ol>
<li><strong>最优化观点</strong>，生成模型就是在非监督数据集上根据这种观点被训练的。它为高度非线性参数估计难题提供了极好的初始化参数（通常深度网络中使用的名词“预训练”就是因此被引入的）。</li>
<li><strong>正则化观点</strong>，据此非监督学习模型能有效的提供一个在一组模型函数集上的先验。</li>
</ol>
<p>下面提供关于这类模型相关的参考文献，相信大家可以从中学习到比较深入的知识。</p>
<p><em>[1]    D. Erhan, Y. Bengio, A. Courvelle, P.Manzagol, P. Vencent, and S. Bengio.Why does unsupervised pre-training help deep learning? Journal on Machine Learning Research, pages 201–208, 2010.<br>[2]    D. Erhan, Y. Bengio, A. Courvelle, P.Manzagol, P. Vencent, and S. Bengio.Why does unsupervised pre-training help deep learning? Journal on Machine Learning Research, pages 201–208, 2010.<br>[3]    A. Mohamed, D. Yu, and L. Deng. Investigation of full-sequence training of deep belief networks for speech recognition. In Proceedings of Interspeech. 2010.<br>[4]    B. Kingsbury, T. Sainath, and H. Soltau. Scalable minimum bayes risk training of deep neural network acoustic models using distributed hessian-free optimization. In Proceedings of Interspeech. 2012.<br>[5]    M. Ranzato, J. Susskind, V. Mnih, and G. Hinton. On deep generative models with applications to recognition. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2011.<br>[6]    H. Lee, R. Grosse, R. Ranganath, and A. Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations.In Proceedings of International Conference on Machine Learning (ICML). 2009.</em><br>在接下来的一篇文章中，我们将详细说明三种深度学习领域典型类型的模型。给出简单的结构描述和数学描述。这三种举例的模型可能不一定是最具代表性和有影响力的模型，不过可以作为一种说明来让大家明白区别。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p> <img src="/imgs/nn2.jpg" alt=""></p>
<h1 id="三类深度学习网络"><strong>三类深度学习网络</strong></h1>
<p>本篇介绍深度学习的大致分类，根据其应用方式的不同，我们可以粗分类几种不同结构的深度学习方法。</p>
<h2 id="(1)_三种深度学习网络分类方式">(1)   三种深度学习网络分类方式</h2>
<p>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://goldencui.org/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://goldencui.org/tags/Deep-Learning/"/>
    
      <category term="DL&amp;ML" scheme="http://goldencui.org/categories/DL&ML/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[简明深度学习方法概述（一）]]></title>
    <link href="http://goldencui.org/2014/12/02/%E7%AE%80%E6%98%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://goldencui.org/2014/12/02/简明深度学习方法概述（一）/</id>
    <published>2014-12-02T10:09:00.000Z</published>
    <updated>2014-12-02T11:30:52.000Z</updated>
    <content type="html"><![CDATA[<p> <img src="/imgs/nn0.jpg" alt=""><br><em>说明：本文主要是翻译整理Li Deng 和 Dong Yu所著的《Deep Learning：Methods and Application》文章并没有全文翻译，而是一个总结并加入个人理解生成的概括性文章。如果要深入了解推荐读原文。博主真心能力有限，所以理解之处错误在所难免，请勿喷。</em></p>
<h1 id="一、_综述"><strong>一、    综述</strong></h1>
<p><a id="more"></a><br>在这片介绍性文章开始，先简单介绍一下深度学习的概念。深度学习（Deap Learning），是机器学习的一个新的研究领域，它的定义有很多，这里随意列举一两个定义你们感受一下（老外的语言还是很干练的）：</p>
<p><em>1) “A class of machine learning techniques that exploit many layers of non-linear information processing for supervised or unsupervised feature extraction and transformation, and for pattern analysis and classification.”<br>2) “deep learning is a set of algorithms in machine learning that attempt to learning in multiple levels, corresponding to different levels of abstraction. It typically uses artificial neural networks. The levels in these learned statistical models correspond to distinct levels of concepts, where higher-level concepts are defined from lower-level ones, and the same lower-level concepts can help to define many higher-level concepts”</em><br>上述英文定义的共同点包括两个主要方面：</p>
<ol>
<li>模型由多个层次或多个非线性信息处理模块阶段组成</li>
<li>特征表示的监督和非监督学习方法在深度模型的更高抽象层次里</li>
</ol>
<p>深度学习是多学科领域的交叉，比如神经网络、人工智能、图建模、最优化理论、模式识别和信号处理。需要注意的是本文所描述的深度学习是在信号和信息处理内容中学习出一种深度结构。它不是对信号和信息处理知识的理解，尽管某些意义上说它俩相似，但深度学习重点在于学习出一种深度网络结构，是实实在在存在的一种计算机可存储结构，这种结构表示了信号的某种意义上的内涵。<br>从06年开始，深度结构学习方法（深度学习或者分层学习方法）作为机器学习领域的新的研究方向出现。由于三种主要领域的技术进步（比如芯片处理性能的巨大提升，数据爆炸性增长和机器学习与信信号处理研究的进步），在过去的短短几年时间，深度学习技术得到快速发展，已经深深的影响了学术领域，其研究涉及的应用领域包括计算机视觉、语音识别、对话语音识别、图像特征编码、语意表达分类、自然语言理解、手写识别、音频处理、信息检索、机器人学。<br>由于深度学习在众多领域表现比较好的性能，越来越多的学术机构把目光投入深度学习领域。今年来活跃在机器学习领域的研究机构包括众多高校比如斯坦福，伯克利，还有一些企业例如Google，IBM 研究院，微软研究院，FaceBook，百度等等。这些研究机构在计算机领域的众多应用中都成功利用了深度学习方法，甚至有一个关于分子生物学的研究指出他们利用深度学习方法引领下发现了新的药物。<br>本文只是阐述了截止2014年最新的有关深度学习研究的一部分内容综述，如果需要了解这个领域的最新进展，推荐到以下网址获取：</p>
<ul>
<li><a href="http://deeplearning.net/reading-list/" target="_blank" rel="external">http://deeplearning.net/reading-list/</a></li>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/UFLDL_Recommended_Readings" target="_blank" rel="external">http://ufldl.stanford.edu/wiki/index.php/UFLDL_Recommended_Readings</a></li>
<li><a href="http://www.cs.toronto.edu/∼hinton/" target="_blank" rel="external">http://www.cs.toronto.edu/∼hinton/</a></li>
<li><a href="http://deeplearning.net/tutorial/" target="_blank" rel="external">http://deeplearning.net/tutorial/</a></li>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial" target="_blank" rel="external">http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial</a></li>
</ul>
<h1 id="二、_深度学习历史"><strong>二、    深度学习历史</strong></h1>
<p>直到近些年，大多数机器学习和信号处理技术大多还是采用浅层的结构，这些典型结构包含至多一层或两层非线性特征变换。这种浅层结构的代表比如高斯混合模型（GMM），线性或非线性动态系统，条件随机场（CRFs），最大熵模型，支持向量机（SVMs），逻辑回归（LR），核回归，多层感知器（MLPS）。例如，SVMs 使用了一个浅层的线性模式分类器，当使用核技巧的话，包含一个特征转换层。浅层结构方法（既机器学习方法）已经在一些简单和有限制难题中得到了比较好的结果，但是当处理复杂的现实世界的问题时（例如语音，自然声音图像，语言，视场等），它们有限的模型复杂度和表达能力就遇到了困难。<br>人类自我信息的处理和理解（例如视觉信息，声音信息），一直以来都比较复杂，因此需要更深的结构算法从输入层中提取特征。比如说，语音生成和理解系统在把波形信号转变成语言级别的信号的时候，就是设置了清晰的多层结构去学习。历史上来看，深度学习的概念起源于神经网络的研究。含有多隐层的前馈神经网络（BP）或者多层感知器（多隐层MLPs通常指深度神经网络DNNs），就是一个深度结构模型的例子。BP神经网络流行在上世纪80年的，已经成为广为人知的学习算法。遗憾的是，加入多隐层的BP神经网络算法效果却并不好（网络中普遍存在的非凸目标函数的局部最优化调整问题是主要的训练难题）。随着网络深度的增加，越难达到局部最优化。而这个困境的原因是忽视了机器学习和信号处理领域的研究，比如机器学习方法中的SVM,CRF,和最大熵模型，包含损失函数，使用这些方法可以有效获得全局优化。<br>深信网络（deep belief network DBN）提出后，深度模型的最优化困难可以在经验上得到降低。DBN是由一组限制玻尔兹曼机（RBMs）组成的层次网络学习算法，它可以在线性的时间复杂度内达到模型参数的最优化。使用MLP采用合理配置初始化权值后，DBN经常能表现的比随机参数更好一点。同理，含多隐层的MLPs 或者深度神经网络（DNN）学术上也被称为DBNs。最近，研究人员已经更精细的区分DNNs和DBNs，如果使用DBN去初始化DNN的训练的话，那么这个网络就可以被称为DBN-DNN。这上述的深度学习的理论提出后，学术界不断提出改进的理论来丰富深度学习的内容，深度学习理论已经得到了极大的丰富和发展。<br>我们可以从另一个角度来了解这个发展历程，下图展现了不同时代的神经网络被宣传的热度。巅峰期出现在1980s和1990s，此时被称为神经网络的第二代。DBN在06年被研究出来，当DBN被用在初始化DNN的时候，学习算法的效率就变的更加有效，这促进了学术界连续的快速研究成果。DBN和DNN的产业级语音特征提取和识别应用出现在09年，当时产业界和学术界以及深度学习的研究专家有着密切的相互合作。这种合作快速发展了语音识别的深度学习方法，并由此而取得了巨大成功。<br> <img src="/imgs/nn1.png" alt="industry scale"><br>图中“plateau of productivity（稳定产出）”短语目前还没有到来，但是期望在未来将会比图中显示出的走势更加剧烈，像标记中的虚线那样，而我们就是刚刚处于这个时期，尤其最近深度学习概念屡屡被热炒，其发展热度可见一斑。</p>
<p><em>未完待续…</em></p>
]]></content>
    <summary type="html">
    <![CDATA[<p> <img src="/imgs/nn0.jpg" alt=""><br><em>说明：本文主要是翻译整理Li Deng 和 Dong Yu所著的《Deep Learning：Methods and Application》文章并没有全文翻译，而是一个总结并加入个人理解生成的概括性文章。如果要深入了解推荐读原文。博主真心能力有限，所以理解之处错误在所难免，请勿喷。</em></p>
<h1 id="一、_综述"><strong>一、    综述</strong></h1>
<p>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://goldencui.org/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://goldencui.org/tags/Deep-Learning/"/>
    
      <category term="DL&amp;ML" scheme="http://goldencui.org/categories/DL&ML/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[程序员与画家]]></title>
    <link href="http://goldencui.org/2014/10/30/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%B8%8E%E7%94%BB%E5%AE%B6/"/>
    <id>http://goldencui.org/2014/10/30/程序员与画家/</id>
    <published>2014-10-30T02:46:05.000Z</published>
    <updated>2014-10-30T03:32:14.000Z</updated>
    <content type="html"><![CDATA[<p><img src="/imgs/h.jpg" alt="" title="黑客与画家"><br>程序猿与画家到底什么联系？《黑客与画家》这本书应该给了一些提示。写程序的大抵在程序从需求分析，到编码，到调试，到测试，到最终验收的各个阶段，其实都和绘画这种古老有趣的艺术是相同的。绘画也要经历构思，构图，绘制，修改，到最后成稿。这期间的种种，都包含程序员和画家的心血和想象力。<br><a id="more"></a><br>有时候我会想程序员就是一个艺术家，程序员在世间的地位往往被形容为码农，和搬砖的一个地位，表面总是不会光鲜靓丽，而我们也乐此不疲的自黑。但是和画家一样，在笔触描绘<br>的一点一顿中，画家把自己思想，把自己的情感融入一幅幅绚丽多彩的画面中，把自己的生活感悟生成永恒的画面。程序员则融入自己的心血和创造力，一步步的逻辑和点滴的巧妙设置，就如同画家对阴影，细节的处理一样，虽然没有画笔表现出的视觉直观，但是隐藏在程序背后的二进制，是世界上最精巧的艺术！它隐藏了细节，隐藏了内部的惊奇与壮观，给了你最直观的壮观的体验和方便。<br>程序员骨子里是文艺的，或者本质上，一个优秀的程序员，就和艺术家一样，他们创造，他们敢于质疑，他们表现他们手上最酷的东西，梵高在最窘迫的时候，仍然把自己的创造力发挥的淋漓尽致，优秀的程序员在几尺见方的格子里，消耗自己的健康和薯片，改变世界，一流的程序员总能改变世界的。<br>现在想来，我最早的痴迷绘画，真是一种宿命一样，我喜欢绘画，喜欢埋头填充白色纸面的那种感觉。当我拿起画笔的时候，时间就像静止一样，我可以在那种万籁俱静一样的另一个时空里，感受内心的平静，那个时候我是最本真的我。最早的梦想就是成为一个画家，像莫奈和毕加索，想达芬奇。但谁能想到我未来的职业是和程序算法相关呢？绘画给了我另一种体会世界的方式和眼光，他给了我在喧嚣世界里掩藏内心，不忘初心的方式。算法和程序给了认识世界的另一种方式，这个世界除了彩色和画面构成以外，还需要自然规律和逻辑支撑 。<br>下面是我闲事的随笔作品，我会坚持画下去，虽然距离当一名画家的梦想太过遥远。不过套用一句时髦的话，梦想还是要有的，万一实现了呢?</p>
<hr>
<h2><img src="/imgs/1.jpg" alt="余晖" title="余晖"></h2>
<h2 id="-1"><img src="/imgs/2.jpg" alt="梦境" title="梦境"></h2>
<h2 id="-1"><img src="/imgs/3.jpg" alt="鲸鱼" title="鲸鱼"></h2>
<p><img src="/imgs/4.jpg" alt="夜" title="夜"></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="/imgs/h.jpg" alt="" title="黑客与画家"><br>程序猿与画家到底什么联系？《黑客与画家》这本书应该给了一些提示。写程序的大抵在程序从需求分析，到编码，到调试，到测试，到最终验收的各个阶段，其实都和绘画这种古老有趣的艺术是相同的。绘画也要经历构思，构图，绘制，修改，到最后成稿。这期间的种种，都包含程序员和画家的心血和想象力。<br>]]>
    
    </summary>
    
      <category term="艺术" scheme="http://goldencui.org/tags/%E8%89%BA%E6%9C%AF/"/>
    
      <category term="随笔" scheme="http://goldencui.org/categories/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[网络资源搜索爬虫(python 3.4.1实现)]]></title>
    <link href="http://goldencui.org/2014/10/15/%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90%E6%90%9C%E7%B4%A2%E7%88%AC%E8%99%AB(python%203.4.1%E5%AE%9E%E7%8E%B0)/"/>
    <id>http://goldencui.org/2014/10/15/网络资源搜索爬虫(python 3.4.1实现)/</id>
    <published>2014-10-15T02:16:50.000Z</published>
    <updated>2014-10-15T08:24:18.000Z</updated>
    <content type="html"><![CDATA[<p><img src="http://abstrusegoose.com/strips/how_stuff_works.png" alt="" title="silly man"><br>最近在学习python语言，python以前没有接触，只用过perl，以前使用perl做一些大的数据集处理，当时也是比较生疏，所以一上来看了简单的官方说明文档，就马上开始coding，大约一周基本就对perl的特性比较熟悉了。所以这次我秉持着从实践中学习技术的角度，打算用python做一些小程序，顺便熟悉python语言的各个方面的特性，也因为我对网络爬虫一直都很有些兴趣，就打算着手做个小工具。<br><a id="more"></a><br>使用python做网络爬虫，网上的资源很多，我搞不清为什么很多人和机构都热衷于用python做网络爬虫，大概是因为python在这方面提供的支持库比较多也比较容易实现吧。现有的比较典型的开源爬虫架构如<a href="http://scrapy.org/" target="_blank" rel="external">scrapy</a>（python实现），其实现的功能已经比较全面了，最早的时候想了解网络爬虫的原理的时候，曾经尝试过使用scrapy定制，scrapy已经实现了比较复杂的爬虫功能，官方文档也介绍的很详细。不过为了满足我重复造轮子的好奇心，决定自己做一下,多给脑子里填一些东西</p>
<p>python实现网络爬虫的原理和架构网上资源很多，我就不在这里赘述，大家可以参考这些个链接了解：<br>1.<a href="http://www.zhihu.com/question/20899988" target="_blank" rel="external">如何入门网络爬虫?</a><br>2.<a href="http://www.zhihu.com/question/21358581" target="_blank" rel="external">你是如何开始能写python爬虫？</a></p>
<p>用python 3做网络爬虫可以使用基本的http库也可以使用urllib（注意在python2.7.*以前都是urllib2，更新后urllib2被丢弃）这种库提供对网页url的处理模块。网上充斥着大量的爬虫教程绝大多数部分描述的是使用python2 +urllib2库。使用python3做爬虫还比较少，基本原理是一样的，不过就是urlib库里一些功能的实现和老版本的库稍有不同。<br>简单的使用urllib抓取网页的例子如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line">f = urllib.request.urlopen(<span class="string">'http://www.python.org/'</span>)</div><div class="line">print(f.read().decode(<span class="string">'urf-8'</span>))</div></pre></td></tr></table></figure>

<p>urllib的具体使用接口和方法参加<a href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request" target="_blank" rel="external">官方文档</a>，这里不再详述。<br>对于网络爬虫最很重要的一环，网页页面HTML的处理方法，python官方给出了一些标准库，不过有一个第三方库<a href="http://beautifulsoup.readthedocs.org/en/latest/" target="_blank" rel="external">beautiful soup</a>对抓取的网页分析更加方便，本文所述的程序采用这个库做HTML页面分析和处理。<br>爬虫关键的就是性能问题，影响性能的原因一个是因为爬虫程序搜索网页的逻辑本身耗时，另一个是抓取页面响应时的耗时，前一种耗时可以采用python标准库中的多线程对爬虫程序进行优化，提取主页中的关键URL采用多个爬虫线程进行爬取。针对后一种耗时，可以采用集群的方式对爬虫进行优化，不过本文研究的程序仅仅作为一种学习，不深入讨论。这里指给出优化的一小部分，python多线程的实例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> threading, zipfile</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsyncZip</span><span class="params">(threading.Thread)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, infile, outfile)</span>:</span></div><div class="line">        threading.Thread.__init__(self)</div><div class="line">        self.infile = infile</div><div class="line">        self.outfile = outfile</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></div><div class="line">        f = zipfile.ZipFile(self.outfile, <span class="string">'w'</span>, zipfile.ZIP_DEFLATED)</div><div class="line">        f.write(self.infile)</div><div class="line">        f.close()</div><div class="line">        print(<span class="string">'Finished background zip of:'</span>, self.infile)</div><div class="line"></div><div class="line">background = AsyncZip(<span class="string">'mydata.txt'</span>, <span class="string">'myarchive.zip'</span>)</div><div class="line">background.start()</div><div class="line">print(<span class="string">'The main program continues to run in foreground.'</span>)</div><div class="line"></div><div class="line">background.join()    <span class="comment"># Wait for the background task to finish</span></div><div class="line">print(<span class="string">'Main program waited until background was done.'</span>)</div></pre></td></tr></table></figure>

<p>本文描述的爬虫主要功能是在给定的某个主页下进行广度搜索，找到子页面和父页面中包含的所有pdf和doc/docx文档并下载。之所以做这样的一个工具是因为最近在看一些论文，经常一些学术性网站会放出论文的pdf版本，不过由于pdf文件在网页中分布比较分散，手工下载起来比较麻烦，因此尝试自动爬取网页中的这些资源，然后再逐个检索。<br>爬虫的GUI框架使用<a href="http://www.tkdocs.com/tutorial/index.html" target="_blank" rel="external">Tkinter</a>，Tkinter支持很多语言，比如ruby，perl，python等，是一个比较简单图形界面库，之所以不采用其他第三方GUI框架是因为这些框架很多只支持python2.7.*以前的版本，而我这里用的python3.4.1，无奈选择了最方便的方法。<br>下面是程序的界面：<br><img src="/imgs/爬虫主界面.PNG" alt="主界面" title="主界面"><br><img src="/imgs/爬虫搜索时.PNG" alt="运行时" title="运行时"><br>下载文件的存储路径在设置按钮内设置，界面真心丑，不过能用…</p>
<p><strong>程序的源码在<a href="https://github.com/pangge/python-crawler-ccw" target="_blank" rel="external">我的github</a>上，欢迎大家交流学习。</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="http://abstrusegoose.com/strips/how_stuff_works.png" alt="" title="silly man"><br>最近在学习python语言，python以前没有接触，只用过perl，以前使用perl做一些大的数据集处理，当时也是比较生疏，所以一上来看了简单的官方说明文档，就马上开始coding，大约一周基本就对perl的特性比较熟悉了。所以这次我秉持着从实践中学习技术的角度，打算用python做一些小程序，顺便熟悉python语言的各个方面的特性，也因为我对网络爬虫一直都很有些兴趣，就打算着手做个小工具。<br>]]>
    
    </summary>
    
      <category term="pthon3.4.1" scheme="http://goldencui.org/tags/pthon341/"/>
    
      <category term="网络爬虫" scheme="http://goldencui.org/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"/>
    
      <category term="python多线程" scheme="http://goldencui.org/tags/python%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
      <category term="python" scheme="http://goldencui.org/categories/python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[windows64位环境下python安装numpy、scipy和matplotlib]]></title>
    <link href="http://goldencui.org/2014/10/02/windows64%E4%BD%8D%E7%8E%AF%E5%A2%83%E4%B8%8Bpython%E5%AE%89%E8%A3%85numpy%E3%80%81scipy%E5%92%8Cmatplotlib/"/>
    <id>http://goldencui.org/2014/10/02/windows64位环境下python安装numpy、scipy和matplotlib/</id>
    <published>2014-10-02T08:47:04.000Z</published>
    <updated>2014-10-15T06:52:06.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>最近想使用python做一些机器学习方向的算法实现，使用python做数据分析和矩阵运算什么的常需要三个库文件：numpy、scipy和matplotlib，于是着手安装。<br>我自己机子的配置是win8+64位操作系统，python安装的版本是3.4.1。安装这几个库首先安装numpy，然后是scipy和matplotlib。<br>查询了numpy的官网后发现根本没有64位，3.4版本python的release版本包，可能是python3.4刚更新的缘故，SourceForge的更新比较慢，还没有最新的发布。scipy和matplotlib也相同，也真是痛苦。<br>上网搜了一些解决方案，当时以为比较简单的问题，直接baidu，结果真是失望，搜索出来的都是无关紧要的内容（原谅我没有google…）。<br>终于在stackoverflow里查到了一些方案，其中一个<a href="http://stackoverflow.com/questions/11200137/installing-numpy-on-64bit-windows-7-with-python-2-7-3" target="_blank" rel="external">install numpy on 64bit win7 with python2.7.3</a>，里面提示了一个<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy" target="_blank" rel="external">资源网站</a>，网站里发布了根据<a href="https://software.intel.com/en-us/intel-mkl" target="_blank" rel="external">Intel® Math Kernel Library</a>第三方生成的最新的python库，进去看了一下，里面很多python可使用的编译好的库。<br>由于我自己python版本是3.4.1，于是选择了这几个文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">numpy-MKL-<span class="number">1.9</span>.<span class="number">0</span>.win-amd64-<span class="keyword">py3</span>.<span class="number">4</span>.<span class="keyword">exe</span></div><div class="line">SciPy-<span class="number">0.13</span>.<span class="number">2</span>.win-AMD64-<span class="keyword">py3</span>.<span class="number">4</span>.<span class="keyword">exe</span></div><div class="line">matplotlib-<span class="number">1.4</span>.<span class="number">0</span>.win-amd64-<span class="keyword">py3</span>.<span class="number">4</span>.<span class="keyword">exe</span></div></pre></td></tr></table></figure>

<p><a id="more"></a>安装numpy的时候一路点进去，安装快要结束的时候出现安装程序崩溃的问题。当时吓了一跳，以为是安装程序不匹配，没办法自己搞虚拟机准备用linux环境下的解决方案。后面无意间在windows下测试了一下numpy是否安装成功<br>结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;<span class="keyword">from</span> numpy <span class="keyword">import</span> <span class="keyword">import</span> *</div><div class="line">&gt;&gt;&gt;a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</div><div class="line">&gt;&gt;&gt;mat(a)</div><div class="line">&gt;&gt;&gt;matrix([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</div></pre></td></tr></table></figure>

<p>艾玛!!!  竟然没有问题，证明numpy安装应该没有错,可以使用，scipy和mat的安装也出现类似问题，不过暂时都不影响使用，不知道后续会不会出问题。之所以程序安装会出现崩溃，我怀疑应该我自己win8系统的错误或者库的兼容性问题。后面还没有完整测试这几个库，不知道是不是其它电脑也会出现类似问题，唉也毕竟是第三方的库，多有不兼容的地方还是很正常的。</p>
<p>linux环境下的话，可以下载numpy和scipy的源码直接自己编译，不过需要安装MKL，因为本人已经不用linux很久了，所以也没有仔细阅读具体方法，<a href="https://software.intel.com/zh-cn/articles/numpyscipy-with-intel-mkl" target="_blank" rel="external">这里</a>有很清晰的流程说明。</p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>最近想使用python做一些机器学习方向的算法实现，使用python做数据分析和矩阵运算什么的常需要三个库文件：numpy、scipy和matplotlib，于是着手安装。<br>我自己机子的配置是win8+64位操作系统，python安装的版本是3.4.1。安装这几个库首先安装numpy，然后是scipy和matplotlib。<br>查询了numpy的官网后发现根本没有64位，3.4版本python的release版本包，可能是python3.4刚更新的缘故，SourceForge的更新比较慢，还没有最新的发布。scipy和matplotlib也相同，也真是痛苦。<br>上网搜了一些解决方案，当时以为比较简单的问题，直接baidu，结果真是失望，搜索出来的都是无关紧要的内容（原谅我没有google…）。<br>终于在stackoverflow里查到了一些方案，其中一个<a href="http://stackoverflow.com/questions/11200137/installing-numpy-on-64bit-windows-7-with-python-2-7-3" target="_blank" rel="external">install numpy on 64bit win7 with python2.7.3</a>，里面提示了一个<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy" target="_blank" rel="external">资源网站</a>，网站里发布了根据<a href="https://software.intel.com/en-us/intel-mkl" target="_blank" rel="external">Intel® Math Kernel Library</a>第三方生成的最新的python库，进去看了一下，里面很多python可使用的编译好的库。<br>由于我自己python版本是3.4.1，于是选择了这几个文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">numpy-MKL-<span class="number">1.9</span>.<span class="number">0</span>.win-amd64-<span class="keyword">py3</span>.<span class="number">4</span>.<span class="keyword">exe</span></div><div class="line">SciPy-<span class="number">0.13</span>.<span class="number">2</span>.win-AMD64-<span class="keyword">py3</span>.<span class="number">4</span>.<span class="keyword">exe</span></div><div class="line">matplotlib-<span class="number">1.4</span>.<span class="number">0</span>.win-amd64-<span class="keyword">py3</span>.<span class="number">4</span>.<span class="keyword">exe</span></div></pre></td></tr></table></figure>

<p>]]>
    
    </summary>
    
      <category term="numpy" scheme="http://goldencui.org/tags/numpy/"/>
    
      <category term="scipy" scheme="http://goldencui.org/tags/scipy/"/>
    
      <category term="matplotlib" scheme="http://goldencui.org/tags/matplotlib/"/>
    
      <category term="python" scheme="http://goldencui.org/tags/python/"/>
    
      <category term="win64" scheme="http://goldencui.org/tags/win64/"/>
    
      <category term="python" scheme="http://goldencui.org/categories/python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[基于FPGA的SOPC系统设计tips]]></title>
    <link href="http://goldencui.org/2014/09/26/%E5%9F%BA%E4%BA%8EFPGA%E7%9A%84SOPC%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1tips/"/>
    <id>http://goldencui.org/2014/09/26/基于FPGA的SOPC系统设计tips/</id>
    <published>2014-09-26T09:57:53.000Z</published>
    <updated>2014-10-15T06:54:55.000Z</updated>
    <content type="html"><![CDATA[<p> 之前做了半年的基于FPGA的SOPC的研究，期间遇到很多问题，对于我这个以前只搞过软件的人来说简直是一种折磨，从最简单的串口信息获取，到FPGA外设驱动,这期间遇到很多困难，好在老天有眼一一克服，这篇文章零散的记录基于FPGA嵌入式PPC440微处理器+standalone模式下系统编程方面的操作，以tips为形式展现，只列出系统构建过程中遇到的问题以及解决方法。一些XILINX官网可以查到的技术资料这里暂且不提，后面会附上链接。</p>
<h2 id="1-_浮点数据串口输出">1. 浮点数据串口输出</h2>
<p>XILINX公司提供的标准c一部分实现，并不是所有。它提供的标准串口输出函数包括xil_printf(),printnum();前一个函数和标准c相似，printnum()输出数字型数据。但是自己项目中涉及到浮点型数据的展示，所以想着xil_printf(“%f”,float_data)，发现根本不行，检查了xil_print()的源码，发现根本没有浮点输出的模式（orz…）。<br>仔细检查了XILINX SDK的技术文档，发现它提供了另一个标准函数的实现sprintf()，和print()函数，print()函数就是打印字符类型数据，所以我们可以把浮点类型数据转变为char*字符串，然后输出。所以包装一下，加入了double型和float型数据的打印程序：<br><a id="more"></a></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> print_double(<span class="keyword">double</span> f)</div><div class="line">{</div><div class="line">	<span class="keyword">char</span> out[<span class="number">40</span>];</div><div class="line">	<span class="keyword">char</span> *output=out;</div><div class="line">	<span class="built_in">sprintf</span>(output,<span class="string">"%.3f"</span>,f);</div><div class="line">	print(out);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">void</span> print_float(<span class="keyword">float</span> f)</div><div class="line">{</div><div class="line">	<span class="keyword">char</span> out[<span class="number">20</span>];</div><div class="line">	<span class="keyword">char</span> *output=out;</div><div class="line">	<span class="built_in">sprintf</span>(output,<span class="string">"%.3f"</span>,f);</div><div class="line">	print(out);</div><div class="line">}</div></pre></td></tr></table></figure>

<h2 id="2-_Sqrt函数问题">2. Sqrt函数问题</h2>
<p>程序中遇到过一个地方需要sqrt()调用，一般思路是：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Double_result=<span class="built_in">sqrt</span>(double_data);</div></pre></td></tr></table></figure>

<p>程序一运行我就哭了，崩溃。。。。仔细测试了很多方法，发现这种模式可行：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">u32_result=<span class="built_in">sqrt</span>(u32_data);</div></pre></td></tr></table></figure>

<p>可惜u32类型类似整形，会对小数位截断，这样得不到精确的解，于是尝试改进得到一个可以运行的模式：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">u32_result=<span class="built_in">sqrt</span>((<span class="keyword">double</span>)u32_data);</div></pre></td></tr></table></figure>

<p>可行，但是还不满意，得到结果还是整形；突然想到我们系统需求是小数点2位精确，这样的话可以采取这样的形式解决：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">u32_data=u32_data*<span class="number">10000</span>;</div><div class="line">u32_result=<span class="built_in">sqrt</span>(u32_data);</div><div class="line">double_result=(<span class="keyword">double</span>)u32_result/<span class="number">100</span>;</div></pre></td></tr></table></figure>

<h2 id="3-_DDR2_读写_">3. DDR2 读写 </h2>
<p>首先在硬件系统结构设计的时候，加入DDR2外设，得到DDR2存储的base_address，然后再standalone模式中加入实现。<br>读：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">u32_DDR2_addr = base_address; (例如：<span class="number">0x00000000</span>)</div><div class="line">u32_word = u32_DDR2_addr[u32_index];</div></pre></td></tr></table></figure>

<p>写：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">u32_DDR2_addr[u32_index] = u32_word;</div></pre></td></tr></table></figure>

<h2 id="4-_PPC440_微处理器时间获取">4. PPC440 微处理器时间获取</h2>
<p>在XPS上进行硬件系统设计的采用的PPC440主频是125MHZ。XILINX内并未实现标准操作系统的timer功能，所以查阅了XILINX提供的源码找到一种提供计时的方法：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">u32 ReadTimer()</div><div class="line">{</div><div class="line">	u32 timeCount;</div><div class="line">	timeCount=XTmrCtr_ReadReg(InstancePtr.BaseAddress,</div><div class="line">					 TmrCtrNumber, XTC_TCR_OFFSET);</div><div class="line">	<span class="keyword">return</span> timeCount;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">void</span> InitTimer()</div><div class="line">{</div><div class="line">	InstancePtr.BaseAddress=TIMER_ADDR; <span class="comment">//timer addr</span></div><div class="line">	TmrCtrNumber=TIMER_NUM; <span class="comment">// timer number</span></div><div class="line">	<span class="comment">/*</span></div><div class="line">	 * Reset the timer and the interrupt</div><div class="line">	 */</div><div class="line">	XTmrCtr_WriteReg(InstancePtr.BaseAddress, TmrCtrNumber,</div><div class="line">			  XTC_TCSR_OFFSET,</div><div class="line">			  XTC_CSR_INT_OCCURED_MASK | XTC_CSR_LOAD_MASK);</div><div class="line"></div><div class="line"></div><div class="line">	<span class="comment">/*</span></div><div class="line">	 * Set the control/status register to enable timer</div><div class="line">	 */</div><div class="line">	XTmrCtr_WriteReg(InstancePtr.BaseAddress, TmrCtrNumber,</div><div class="line">			  XTC_TCSR_OFFSET, XTC_CSR_ENABLE_TMR_MASK);</div><div class="line">}</div></pre></td></tr></table></figure>

<p>使用计时方法的时候首先需要调用一次InitTimer()，然后在计数器开启的状态下可以调用ReadTimer()读计数器寄存器.<br>例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">InitTimer(); <span class="comment">// initial  timer	</span></div><div class="line">Todo module</div><div class="line">u32_TimerCount =ReadTimer();</div></pre></td></tr></table></figure>

<p>这里得到的u32_TimerCount是PPC的指令计数，得到精确的描述还需要如下处理：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">u32 sec_time = u32_TimerCount/<span class="number">125000000</span>; <span class="comment">//(ppc440 主频125MHZ)</span></div></pre></td></tr></table></figure>

<p>资源：<br><a href="http://tgoogle.xilinx.com/search?q=SDK+DVI&amp;btnG=New+Search&amp;getfields=*&amp;numgm=5&amp;filter=0&amp;proxystylesheet=support&amp;client=support&amp;getfields=*&amp;num=200&amp;oe=UTF-8&amp;ie=UTF-8&amp;output=xml_no_dtd&amp;requiredfields=-Archived%3Atrue&amp;show_dynamic_navigation=1&amp;sort=date%3AD%3AL%3Ad1&amp;lang2search=&amp;wc=200&amp;wc_mc=1&amp;ud=1&amp;exclude_apps=1&amp;site=Answers_Docs_Forums" target="_blank" rel="external">xilinx 资源搜索</a><br><a href="http://www.xilinx.com/support/documentation/sw_manuals/xilinx12_1/SDK_Doc/tasks/sdk_t_create_new_appln.htm" target="_blank" rel="external">xilnx sdk嵌入式开发 官方指导</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p> 之前做了半年的基于FPGA的SOPC的研究，期间遇到很多问题，对于我这个以前只搞过软件的人来说简直是一种折磨，从最简单的串口信息获取，到FPGA外设驱动,这期间遇到很多困难，好在老天有眼一一克服，这篇文章零散的记录基于FPGA嵌入式PPC440微处理器+standalone模式下系统编程方面的操作，以tips为形式展现，只列出系统构建过程中遇到的问题以及解决方法。一些XILINX官网可以查到的技术资料这里暂且不提，后面会附上链接。</p>
<h2 id="1-_浮点数据串口输出">1. 浮点数据串口输出</h2>
<p>XILINX公司提供的标准c一部分实现，并不是所有。它提供的标准串口输出函数包括xil_printf(),printnum();前一个函数和标准c相似，printnum()输出数字型数据。但是自己项目中涉及到浮点型数据的展示，所以想着xil_printf(“%f”,float_data)，发现根本不行，检查了xil_print()的源码，发现根本没有浮点输出的模式（orz…）。<br>仔细检查了XILINX SDK的技术文档，发现它提供了另一个标准函数的实现sprintf()，和print()函数，print()函数就是打印字符类型数据，所以我们可以把浮点类型数据转变为char*字符串，然后输出。所以包装一下，加入了double型和float型数据的打印程序：<br>]]>
    
    </summary>
    
      <category term="SOPC" scheme="http://goldencui.org/tags/SOPC/"/>
    
      <category term="XILINX" scheme="http://goldencui.org/tags/XILINX/"/>
    
      <category term="PPC" scheme="http://goldencui.org/tags/PPC/"/>
    
      <category term="嵌入式" scheme="http://goldencui.org/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[git基础命令总结]]></title>
    <link href="http://goldencui.org/2014/07/28/git%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/"/>
    <id>http://goldencui.org/2014/07/28/git基础命令总结/</id>
    <published>2014-07-27T16:15:26.000Z</published>
    <updated>2014-10-15T06:52:38.000Z</updated>
    <content type="html"><![CDATA[<h4 id="（针对ssh方式）"><em>（针对ssh方式）</em></h4>
<hr>
<h1 id="1_github_代码提交">1  github 代码提交</h1>
<p><strong>创建新的版本库</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">touch README.md</div><div class="line"><span class="variable">$git</span> init</div><div class="line"><span class="variable">$git</span> add README.md</div><div class="line"><span class="variable">$git</span> commit -<span class="keyword">m</span> <span class="string">"first commit"</span></div><div class="line"><span class="variable">$git</span> remote add origin git<span class="variable">@github</span>.com:youname/youproject.git</div><div class="line"><span class="variable">$git</span> <span class="keyword">push</span> -u origin master</div></pre></td></tr></table></figure>

<p><strong>推送现有的版本库</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$git</span> remote add origin git<span class="variable">@github</span>.com:youname/youproject.git</div><div class="line"><span class="variable">$git</span> <span class="keyword">push</span> -u origin master</div></pre></td></tr></table></figure>

<p><strong>添加修改的版本库</strong><br><a id="more"></a></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$git</span> add . <span class="comment">// .表示添加所有文件 </span></div><div class="line"><span class="variable">$git</span> commit -m <span class="string">"修改日志"</span></div><div class="line"><span class="variable">$git</span> push -u origin master</div></pre></td></tr></table></figure>

<p><strong><em>错误解决</em></strong></p>
<hr>
<h4 id="1-运行：">1.运行：</h4>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="title">git</span> remote add origin git<span class="variable">@github</span>.com:youname/youproject.git</div></pre></td></tr></table></figure>

<p>错误提示：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fata<span class="variable">l:</span> remote origin already <span class="built_in">exists</span>.</div></pre></td></tr></table></figure>

<p>解决办法：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$git</span> remote rm origin</div></pre></td></tr></table></figure>

<h4 id="2-运行：">2.运行：</h4>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="variable">$ </span>git push origin master</div></pre></td></tr></table></figure>

<p>错误提示：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">error</span>:failed <span class="keyword">to</span> push som refs <span class="keyword">to</span></div></pre></td></tr></table></figure>

<p>解决办法：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ git pull origin master <span class="comment">// 先把远程服务器中版本拉取下来，再push</span></div></pre></td></tr></table></figure>

<hr>
<h1 id="2_github_代码clone">2  github 代码clone</h1>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>git clone git<span class="variable">@github</span>.<span class="symbol">com:</span>youname/youproject.git  <span class="string">"path"</span> /<span class="regexp">/ path 要存放本地版本库的地址</span></div></pre></td></tr></table></figure>

<p><img src="http://github.global.ssl.fastly.net/images/modules/logos_page/Octocat.png" alt="GitHub" title="GitHub cat"></p>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="（针对ssh方式）"><em>（针对ssh方式）</em></h4>
<hr>
<h1 id="1_github_代码提交">1  github 代码提交</h1>
<p><strong>创建新的版本库</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">touch README.md</div><div class="line"><span class="variable">$git</span> init</div><div class="line"><span class="variable">$git</span> add README.md</div><div class="line"><span class="variable">$git</span> commit -<span class="keyword">m</span> <span class="string">"first commit"</span></div><div class="line"><span class="variable">$git</span> remote add origin git<span class="variable">@github</span>.com:youname/youproject.git</div><div class="line"><span class="variable">$git</span> <span class="keyword">push</span> -u origin master</div></pre></td></tr></table></figure>

<p><strong>推送现有的版本库</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$git</span> remote add origin git<span class="variable">@github</span>.com:youname/youproject.git</div><div class="line"><span class="variable">$git</span> <span class="keyword">push</span> -u origin master</div></pre></td></tr></table></figure>

<p><strong>添加修改的版本库</strong><br>]]>
    
    </summary>
    
      <category term="github" scheme="http://goldencui.org/tags/github/"/>
    
      <category term="代码托管" scheme="http://goldencui.org/categories/%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[(ZZ)休息，休息一会儿]]></title>
    <link href="http://goldencui.org/2014/07/26/%E4%BC%91%E6%81%AF%EF%BC%8C%E4%BC%91%E6%81%AF%E4%B8%80%E4%BC%9A%E5%84%BF/"/>
    <id>http://goldencui.org/2014/07/26/休息，休息一会儿/</id>
    <published>2014-07-26T04:01:39.000Z</published>
    <updated>2014-09-26T11:07:35.000Z</updated>
    <content type="html"><![CDATA[<p><img src="http://www.yinwang.org/images/yixiu.jpg" alt="" title="一休哥 1"></p>
<p>本人进入了比较长的，理所应得的休息和娱乐时间。无聊时也看看闲书和电影。这里推荐几个最近看的东西。</p>
<h1 id="《The_Design_of_Everyday_Things》">《The Design of Everyday Things》</h1>
<hr>
<p>最近给我最大影响的是这本1988年出版的《<a href="http://www.amazon.com/Design-Everyday-Things-Revised-Expanded-ebook/dp/B00E257T6C" target="_blank" rel="external">The Design of Everyday Things</a>》（简称DOET）。有趣的是，它的作者 Don Norman 曾经是 Apple Fellow，也是《<a href="http://web.mit.edu/~simsong/www/ugh.pdf" target="_blank" rel="external">The Unix-Haters Handbook</a>》一书序言的作者。<br><a id="more"></a><br>DOET 不但包含并且支持了我的博文《<a href="http://www.yinwang.org/blog-cn/2014/04/11/hacker-culture" target="_blank" rel="external">黑客文化的精髓</a>》以及《<a href="http://www.yinwang.org/blog-cn/2014/01/25/pl-and" target="_blank" rel="external">程序语言与……</a>》里的基本观点，而且提出了比《<a href="http://www.yinwang.org/blog-cn/2012/05/18/user-friendliness" target="_blank" rel="external">什么是“对用户友好”</a>》更精辟可行的解决方案。</p>
<p>我觉得这应该是每个程序员必读的书籍。为什么每个程序员必读呢？因为虽然这本书是设计类专业的必读书籍，而计算机及其编程语言和工具，其实才是作者指出的缺乏设计思想的“重灾区”。看了它，你会发现很多所谓的“人为错误”，其实是工具的设计不合理造成的。一个设计良好的工具，应该只需要很少量的文档甚至不需要文档。这本书将提供给你改进一切事物的原则和灵感。你会恢复你的人性。</p>
<p>值得一提的是，虽然 Don Norman 曾经是 Apple Fellow，但我觉得 Apple 产品设计的人性化程度与 Norman 大叔的思维高度还是有一定的差距的。</p>
<p>如果你跟我一样不想用眼睛看书，可以到 Audible 买本<a href="http://www.audible.com/pd/Science-Technology/The-Design-of-Everyday-Things-Audiobook/B005I5MDGQ" target="_blank" rel="external">有声书</a>来听。</p>
<h1 id="《The_Conquest_of_Happiness》">《The Conquest of Happiness》</h1>
<hr>
<p>每个人都想得到快乐，但是他们往往误解了快乐的来源，追求了错误的东西，所以大多数人因此得到的是痛苦，并且给其他人带来痛苦。英国哲学家和数学家罗素写于1930年的《<a href="http://www.amazon.com/The-Conquest-Happiness-Bertrand-Russell/dp/0871401622" target="_blank" rel="external">The Conquest of Happiness</a>》就是彻底的分析这些2014现代人的常见问题的。</p>
<p>在第一部分，罗素透彻的分析了几个常见的不快乐的原因：看破红尘，竞争，过度追求刺激，疲劳，嫉妒，罪恶感，被害妄想症，…… 第二部分，他提出了得到快乐的有效方法。</p>
<p>如果你认为自己没有这些问题，或者认为自己懂得这些是怎么回事，请再次反思一下，因为每个人都或多或少有这些问题。特别是我发现，竞争和攀比所带来的不快乐，在中国人里面是很普遍的现象。</p>
<p>另外，很多心理学家，特别是所谓“正向心理学”（positive psychology），也声称研究如何使人快乐，但我发现他们很多只是扯着“快乐”的幌子，开发自己的市场。罗素的思想比他们深刻很多。</p>
<h1 id="大独裁者">大独裁者</h1>
<hr>
<p>谈到人性，我推荐卓别林在电影《<a href="https://www.youtube.com/watch?v=6FMNFvKEy4c" target="_blank" rel="external">大独裁者</a>》里面的最后演讲。他引起了我对技术的价值的思考。有人说，世界不是毁在疯子手里就是毁在工作狂手里，是有一定的道理的。</p>
<h1 id="摩登时代">摩登时代</h1>
<hr>
<p>其实比《大独裁者》更幽默，更有趣，对现代社会更有意义的，是卓别林的《<a href="http://www.amazon.com/Modern-Times-Charlie-Chaplin/dp/B004DARF6A" target="_blank" rel="external">摩登时代</a>》。这样一部1930年代的黑白无声电影，道出了直到2014年的今天，世界上最大的问题：过度工作。<br>现代社会很多人为了所谓的“生存”，把自己变成了一台盲目不停工作的机器。加班加点的干活，并且还试图让别人也变成跟他一样。一切都是为了工作，为了效率，为了“优秀”，为了出人头地。太多的野心，太多的目标，却对身边最简单的乐趣视而不见。试试放慢匆忙的脚步，思考一下自己在干什么吧！</p>
<p>因为这些原因，我继续睡觉，这是拯救世界的最好办法 zZZZ</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="http://www.yinwang.org/images/yixiu.jpg" alt="" title="一休哥 1"></p>
<p>本人进入了比较长的，理所应得的休息和娱乐时间。无聊时也看看闲书和电影。这里推荐几个最近看的东西。</p>
<h1 id="《The_Design_of_Everyday_Things》">《The Design of Everyday Things》</h1>
<hr>
<p>最近给我最大影响的是这本1988年出版的《<a href="http://www.amazon.com/Design-Everyday-Things-Revised-Expanded-ebook/dp/B00E257T6C" target="_blank" rel="external">The Design of Everyday Things</a>》（简称DOET）。有趣的是，它的作者 Don Norman 曾经是 Apple Fellow，也是《<a href="http://web.mit.edu/~simsong/www/ugh.pdf" target="_blank" rel="external">The Unix-Haters Handbook</a>》一书序言的作者。<br>]]>
    
    </summary>
    
      <category term="hacker" scheme="http://goldencui.org/tags/hacker/"/>
    
      <category term="转载" scheme="http://goldencui.org/categories/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
</feed>
