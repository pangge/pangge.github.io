<!DOCTYPE HTML>
<html xmlns:wb="http://open.weibo.com/wb">
<head>
<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fdb61424190f6ff63d2f7155a0801ce6b' type='text/javascript'%3E%3C/script%3E"));
</script>
  <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
  <meta charset="utf-8">
  <meta name="google-site-verification" content="KLZdjUwwq3PbCgU3H6iANTWX72y_nU4xSSH59QKZCPk" />
  <meta name="baidu-site-verification" content="kuYiL0rhWt" />
  <meta name="Keywords" content="崔超文's 个人技术博客 崔超文 崔超文 崔超文">
  
  <title>简明深度学习方法概述（三） | goldencui</title>
  <meta name="author" content="goldencwcui">
  
  <meta name="description" content="goldencwcui：崔超文&#39;s blog；goldencwcui主要涉及语言：c++/c perl python matlab；goldencwcui主要领域：FPGA+SOPC Machine Learning Image processing">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="简明深度学习方法概述（三）"/>
  <meta property="og:site_name" content="goldencui"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="goldencui" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">goldencui</a></h1>
  <h2><a href="/">get a real life</a></h2>
</div>

<div id="menu" class="alignright">
  <div class="alignright">
  <form action="http://www.baidu.com/baidu">
	<input type=text name=word>
	<input type="submit" value="GO">
	<input name=tn type=hidden value="bds">
	<input name=cl type=hidden value="3">
	<input name=ct type=hidden value="2097152">
	<input name=si type=hidden value="www.goldencui.org">
  </form>
  </div>
  <div class="clearfix"></div>
<nav id="main-nav">
   <ul id="button">
     <div class="clearfix"></div>
     
       <li><a id="lia" href="/"><h3>首页</h3></a></li>
     
       <li><a id="lia" href="/archives"><h3>归档</h3></a></li>
     
       <li><a id="lia" href="/About"><h3>关于</h3></a></li>
     
	 <li><a id="rss" href="/atom.xml"><img src="/imgs/rss.png" width="25" height="25" /><b>RSS</b></a></li>
   </ul>
   <div class="clearfix"></div>
  </nav>
</div>


<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-03-02T15:22:15.000Z"><a href="/2015/03/02/简明深度学习方法概述（三）/">3月 2 2015</a></time>
      
      
  
    <h1 class="title">简明深度学习方法概述（三）</h1>
  

    </header>
    <div class="entry">
      
        <p> <img src="/imgs/nn2.jpg" alt=""></p>
<h1 id="深度自编码———-非监督学习"><strong>深度自编码———-非监督学习</strong></h1>
<p>一下介绍了非监督学习深度网络模型，我们以此开始三种类别网络的实例化介绍。<br>深度自编码是一类特别的DNN（不含有类标签），它的输出向量和输入向量维度相同。它常常用来学习一种原始数据的表示或者有效的编码方式，并在隐藏的输入层作为向量的形式表示。注意自编码模型是一种非线性特征提取模型，没有类标签。<a id="more"></a>同样的，特征提取模型目标是保存和更好的表示信息而不是任务分类，经过某些方面来说这两个目标相互联系。<br>一个典型的自编码模型拥有一个可以表示原始数据的输入层或者说叫输入特征向量（比如，图像像素或者声音频谱），一个或者更多表示特征转换的隐藏层，以及一个匹配输入层用来重建的输出层。当隐藏层数量超过一个的时候，自编码模型就认为是深度自编码模型。隐藏层的维度既可以比输入层维度更小（目的是压缩特征）也可以更大（目的是把特征映射到更高维空间）。<br>自编码模型经常使用随机梯度下降法训练参数。尽管这样的方法很有效，但经常在训练带有多隐层的网络的时候有一些基本困难。当一些误差反馈到初始的一些层的时候，误差变得极小，训练变得无效起来。虽然有些其它的更高级的反馈传播方法某种程度上可以去解决这些困难，但是仍然导致低效，尤其是当训练数据有限的时候。但幸运的是，这个难题可以通过把每一层网络昨晚自编码模型进行预训练来解决（引用：G. Hinton, S. Osindero, and Y. Teh. A fast learning algorithm for deep belief nets. Neural Computation, 18:1527–1554, 2006.）。这种策略已经被应用在很多方面比如：使用深度自编码去把图像映射到一个基于短二进制编码的图像检索中，编码文档（称为语意哈希）以及编码频谱类语音特征中。<br><strong>1)    使用深度自编码提取语音特征</strong><br>这里我们回顾一组工作，其发表在（L. Deng, M. Seltzer, D. Yu, A. Acero, A. Mohamed, and G. Hinton.Binary coding of speech spectrograms using a deep autoencoder. In<br>Proceedings of Interspeech. 2010.），这篇文章发展出了使用非监督方式从原始频谱语音数据中提取二进制语音编码的方法自编码模型。这种从模型中提取的依据二进制编码的离散表示法能应用在信息检索或者在语音识别中作为瓶颈特性。<br>包含256种频段和1，3,9或13帧的频谱块生成模型如下图所示。这种称为无向图模型称为Gaussian-Bernoulli RBM（高斯-伯努利受限玻尔兹曼机），它含有一个加高斯噪声的线性参数的可见层和一个包含500到3000二进制隐变量的隐层。学习Gaussian-Bernoulli RBM后，它的隐单元的响应可以作为训练其他Gaussian-Bernoulli RBM的输入。这两个Gaussian-Bernoulli RBM可以组成一个深信网络（deep belief net DBN），这篇论文中使用的DBN表示在图的左侧，两个RBMS被分开表示。<br>这个包含三层隐层的深度自编码模型使用DBN的权矩阵铺开组成。最底下一层使用权矩阵编码输入，上一层使用权矩阵倒序的编码输入。然后此深度自编码模型使用误差反馈来微调以最小化重建误差，如图右边所示。当学习过程结束的时候，一个可变长度的频谱图可以被编码和重构。<br> <img src="/imgs/31.png" alt=""><br><strong>2)    堆叠噪声自编码模型</strong><br>在早期的自编码研究中，编码层维度比输入层维度小。然而，在某些应用领域需要编码层维度更大一些，这些情况下，一些需要一些技术去防止神经网络学习一些琐碎无用的映射函数。使用更高维度隐层和编码层的一个原因是使得自编码模型捕捉到输入数据的更丰富的信息。<br>避免上面提到琐碎映射函数问题的方法包括使用稀疏约束，或者使用随机丢弃方法比如随机的强制某些数值归零，由此引入输入层或者隐层数据噪声。例如，在堆叠噪声自编码模型（详细见，P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P. Manzagol.<br>Stacked denoising autoencoders: Learning useful representations in a<br>deep network with a local denoising criterion. Journal of Machine<br>Learning Research, 11:3371–3408, 2010.）中，随机噪声加在输入数据里。这有几个目的，第一，强制输出匹配原始无失真输入数据，模型能避免学习到琐碎无用函数。第二，噪声随机加入后，学习到的模型在同样畸变的测试数据中将更具鲁棒性。第三，每处畸变输入样本不同，极大的提高了测试集尺寸并因此减轻过拟合线问题。<br><strong>3)    变换自编码模型</strong><br>上述深度自编码模型可以提取稳固的特征向量编码归功于模型中多层的非线性处理过程。然而，这种方法提取到的编码是多种多样的。换句话说，当测试者选择的输入特征向量变化的时候，提取的编码将会改变。有时候需要编码变化是可预测的并且反应获取内容的相对不变性。怀着这种目标的变换自编码模型在图像识别中被提出（G. Hinton, A. Krizhevsky, and S. Wang. Transforming autoencoders. In<br>Proceedings of International Conference on Artificial Neural Networks.<br>2011.）。<br>变换自编码模型的构件是一个被称为“胶囊”的东西，它是一个独立子网络，其提取一个单一参数化特征并且表示一个单一实体（一个可视的或者音频的东西）。变换自编码同时接收输入向量和目标输出向量（通过一个全局变换机制从输入向量变换得到）。一个显示表示全局变换机制假定已知。变换自编码模型的编码层由一些“胶囊”组成。<br>在训练阶段，不同的胶囊学习提取不同的实体以便最小化最终输出和目标输出的误差。<br>除了这里介绍的深度自编码结构以外，这里有很多学术上描述的生成模型只使用数据本身（无分类标签数据），用来自动获取高层特征信息。</p>
<h1 id="预训练深度神经网络———-混合体"><strong>预训练深度神经网络———-混合体</strong></h1>
<p>在此篇里，我们介绍一种广泛使用的混合深度结构————预训练深度神经网络（PDNN）并且讨论一下相关技术以及构建RBM（受限玻尔兹曼机）和DBN（上面描述过）。我们在深度神经网络（DNN）之前讨论混合的DNN实例部分是因为从非监督模型到DNN中间的混合模型再到DNN的过度比较自然。监督学习的属性已经广为人知，因此很容易理解使用了非监督预训练的DNN混合模型。<br>本节参考了最近发布的文章：<br><strong>【1】</strong>G. Dahl, D. Yu, L. Deng, and A. Acero. Context-dependent, pre-trained<br>deep neural networks for large vocabulary speech recognition. IEEE<br>Transactions on Audio, Speech, &amp; Language Processing, 20(1):30–42,<br>January 2012.<br><strong>【2】</strong>G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior,<br>V. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. Deep neural<br>networks for acoustic modeling in speech recognition. IEEE Signal<br>Processing Magazine, 29(6):82–97, November 2012.<br><strong>【3】</strong>D. Yu and L. Deng. Deep learning and its applications to signal and<br>information processing. IEEE Signal Processing Magazine, pages 145–<br>154, January 2011.<br><strong>1)    限制玻尔兹曼机（RBM）</strong><br>限制玻尔兹曼机是一种特殊类型的马尔科夫随机场，它含有一层随机隐藏单元和一层随机可见单元。RBM能表示一个二分图，所有可见的单元链接到所有隐藏单元，而且没有可见—-可见或者隐藏—-隐藏之间的链接。<br><strong>2)    非监督层级预训练</strong><br>这里我们描述如何堆叠RBMs并构成DBN作为DNN预训练的基础。在讨论细节之前，我们首先注意一下由Hinton和Salakhutdinov提出的程序（【1】G. Hinton, S. Osindero, and Y. Teh. A fast learning algorithm for deep<br>belief nets. Neural Computation, 18:1527–1554, 2006.），这是一个更一般的非监督层级预训练。也就是说，不仅RBMs可以堆叠生成深度生成网络，其他类型的神经网络也可以做相同的事情，比如由Bengio提出了使用自编码的一个变体记性预训练生成深度网络（Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layerwise<br>training of deep networks. In Proceedings of Neural Information<br>Processing Systems (NIPS). 2006.）。<br>层次堆叠的RBM可以生成DBN，如下图就是一个这样的例子。堆叠过程如下：当学习一个高斯伯努利RBM（比如连续语音特性的应用）后，我们把当前层的响应作为下一层的训练数据。第二层的响应用作为第三层的输入数据，以此类推。这种层次堆叠的贪婪学习策略已经在文章<strong>【1】</strong>有了理论分析验证。注意这种学习过程是非监督的而且不需要类标签。<br>当用在分类任务的时候，这种预训练模型可以相互连接，并且有识别能力的学习过程可以微调所有连接权提高网络的能力。这种可识别的能力的微调通过添加表示一组表示目标输出数据的最终参数层来实现。然后，反馈调节算法可以调整网络权值来修正参数。最上一层的标签层是什么是根据DNN的应用领域的不同而定。<br><img src="/imgs/32.png" alt=""><br>基于RBM堆叠为RBM的预训练已经在大多数场合得到很好表现。需要指出的是除了这种方式以外还有很多其他方式作为预训练方法。</p>
<p><strong>3)    连接DNNS和HMMS</strong><br>目前讨论的预训练的DNN是一个显著的混合深度网络，它是一个输入向量固定维度的静态分类器。然而，很多实际的模式识别和信息处理难题，包括语音识别，机器翻译，自然语义理解，视频处理和生物信息处理需要连续识别。在连续识别中，输入层和输出层的维度是变化的。<br>基于动态编程操作的隐形马尔科夫模型（HMM）是一个解决这个问题的方便方法。因此，很自然而然的想到结合前馈神经网络和HMM桥接。一个使用DNN解决这个问题的流行结构如下图所示。这个结构成功的应用在了语音识别实验中（G. Dahl, D. Yu, L. Deng, and A. Acero. Context-dependent DBNHMMs<br>in large vocabulary continuous speech recognition. In Proceedings<br>of International Conference on Acoustics Speech and Signal Processing<br>(ICASSP). 2011.）。<br>  <img src="/imgs/33.png" alt=""></p>
<h1 id="深度堆栈网络———-监督学习"><strong>深度堆栈网络———-监督学习</strong></h1>
<p>在识别和分类任务包括语音识别和图像分类中，DNN已经展现了巨大的威力，但是训练一个DNN网络却因为复杂度高而难以计算。尤其是常见的训练DNN的技术涉及计算复杂度高的随机梯度下降法，这很难通过机器并行（CPU）来提高速度。这使得学习变成一个大规模复杂问题。现在可以使用一个单一功能强悍的GPU去训练DNN为基础的包含数十到数百数千小时训练数据的表现很好的语音识别器。然而，现在还不清楚如何使用更大规模的训练数据来提高识别的成功率。J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, Q. Le, M. Mao,<br>M. Ranzato, A. Senior, P. Tucker, K. Yang, and A. Ng. Large scale<br>distributed deep networks. In Proceedings of Neural Information Processing<br>Systems (NIPS). 2012.介绍了一些最近的探索工作。<br>这里我们描述一种新的深度学习结构——-深度堆叠网络（DSN）。这小节基于最近发表的几篇文章并作进一步讨论：<br><strong>【1】</strong>L. Deng and D. Yu. Deep convex network: A scalable architecture for<br>speech pattern classification. In Proceedings of Interspeech. 2011.<br><strong>【2】</strong>L. Deng, D. Yu, and J. Platt. Scalable stacking and learning for building<br>deep architectures. In Proceedings of International Conference on<br>Acoustics Speech and Signal Processing (ICASSP). 2012a.<br><strong>【3】</strong>B. Hutchinson, L. Deng, and D. Yu. A deep architecture with bilinear<br>modeling of hidden representations: Applications to phonetic recognition.<br>In Proceedings of International Conference on Acoustics Speech<br>and Signal Processing (ICASSP). 2012.<br><strong>【4】</strong>B. Hutchinson, L. Deng, and D. Yu. Tensor deep stacking networks.<br>IEEE Transactions on Pattern Analysis and Machine Intelligence,<br>35:1944–1957, 2013.<br>DSN的主要设计概念基于堆叠方法，在L. Breiman. Stacked regression. Machine Learning, 24:49–64, 1996.中有基本概念的描述。堆叠方法首先构建一个单模型函数或分类器，然后把这些函数相互堆叠“堆叠”以便学习复杂的函数或分类器。很多实现堆叠的操作方法在最近被提了出来，主要思想是利用在单一模型中使用可监督的信息。堆叠分类器上层的分类器使用串联结构中的下层分类器的输出以及初始输入中获取新的特征。在这片论文中<br>（W. Cohen and R. V. de Carvalho. Stacked sequential learning. In<br>Proceedings of International Joint Conference on Artificial Intelligence<br>(IJCAI), pages 671–676. 2005.）堆叠模型使用的简单模型是条件随机场（CRF）。添加隐藏状态后，这类深度结构在自然语言处理和语音识别领域（这些应用的训练数据的分割信息位置）应用取得了进一步发展并取得成果。在这片论文中<br>（K. Jarrett, K. Kavukcuoglu, and Y. LeCun. What is the best multistage<br>architecture for object recognition? In Proceedings of International<br>Conference on Computer Vision, pages 2146–2153. 2009.），卷积神经网络也被当做堆叠结构，但是监督信息通常在最终的堆叠模型中并未使用。<br>DSN结构最早在论文<strong>【1】</strong>中提出，当时被作为深度凸网络，用来强调主要学习网络算法中的凸特性。DSN把监督信息用在相互堆叠的基础模型中，模型利用了多层感知器的方便性。在基础模型中，输出单元是线性的而且隐层sigmoidal（反曲函数）非线性。输出层的线性特征能使用较好的凸优化求解。由于在输入和输出之间的封闭限制，输入层权值能高效估计出来。<br>一种基础深度堆叠网络结构<br>如下图所示是一种DSN结构模型，包含可变数量的层次化模型，其中每一个模型都是由一个隐层和两组可训练的权值组成典型的神经网络结构。在图中，只展示了四个此类模型，每个模型都由不同的颜色表示。事实上，在图像和语音分类实验中有数百数千个模型被高效训练着。<br> <img src="/imgs/34.png" alt="此深度堆叠模型使用输入输出堆叠，展示了四个模型堆叠，虚线表示层的复制" title="此深度堆叠模型使用输入输出堆叠，展示了四个模型堆叠，虚线表示层的复制"><br>DSN结构中最低一层模型包含一个线性输入单元的输入层，一个非线性单元的非线性隐层和第二个线性输出单元的线性层。隐藏层使用了sigmoidal非线性函数（当然可以使用其他非线性函数，原理相同，非线性函数保证模型训练出的映射的非线性，否则训练出的映射是线性）。如果DSN用在识别一个图像，输入单元可以适应一组图像像素（或者一组图像特征）。如果用在语音识别，输入单元可以适应一组语音波形样本或者提取的语音波形特征，比如功率谱和倒谱系数。输出单元表示目标的分类信息。例如， DSN用来识别数字，输出可能表示0,1,2,3 等等的数值并采用二进制编码的形式。<br>较低层的权值矩阵我们可以用W表示，连接了线性输入单元和非线性隐层单元。上一层权值矩阵用U表示，连接非线性隐层和线性输出层。权值矩阵U可根据W的值采用均方差训练方法确定封闭解。<br>如上所述，DSN包括一组连接，重叠和层次的模型。其中每个模型有相同的结构。注意的是底层输出单元是临近高层模型的输入单元的子集。具体来说，DSN靠上的一层的输入层包含底层输出层的单元，逻辑上说也包括初始时候的原始图像特征。<br>一个学习好的DSN可以部署在自动分类任务例如帧水平语音通话或者状态分类中。把DSN的输出层连接到HMM或者任何动态可编程设备可以进行连续语音识别任务和其他类型序列模式识别任务。</p>

      
    </div>
    <footer>
      
      <nav id="pagination" >
    
    
    <a href="/2014/12/07/flask-css不能更新的问题/" class="alignright next" >下一页</a>
    
    <div class="clearfix"></div>
    </nav>
        
  
  <div class="categories">
    <a href="/categories/DL&ML/">DL&ML</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Machine-Learning/">Machine Learning</a>, <a href="/tags/Deep-Learning/">Deep Learning</a>
  </div>

        
<div class="bshare-custom icon-medium-plus"><a title="分享到" href="http://www.bShare.cn/" id="bshare-shareto" class="bshare-more">分享到</a><a title="分享到QQ空间" class="bshare-qzone"></a><a title="分享到新浪微博" class="bshare-sinaminiblog"></a><a title="分享到人人网" class="bshare-renren"></a><a title="分享到腾讯微博" class="bshare-qqmb"></a><a title="分享到网易微博" class="bshare-neteasemb"></a><a title="更多平台" class="bshare-more bshare-more-icon more-style-addthis"></a><span class="BSHARE_COUNT bshare-share-count">0</span></div><script type="text/javascript" charset="utf-8" src="http://static.bshare.cn/b/buttonLite.js#style=-1&amp;uuid=&amp;pophcol=2&amp;lang=zh"></script><script type="text/javascript" charset="utf-8" src="http://static.bshare.cn/b/bshareC0.js"></script>
        <div class="ds-thread" data-thread-key="2015/03/02/简明深度学习方法概述（三）/"></div>  

      
      <div class="clearfix"></div>
    </footer>

  </div>
</article>
</div></div>
    <aside id="sidebar" class="alignright">
  <div class="widget tag">
<h3 class="title">公告</h3>
<ul class="entry">
<h3 class="cast">1024，程序员的节日，刚好看完<a href="http://www.ishuhui.com/archives/3634" title="one piece">one piece更新</a>，算是庆祝了。话说罗的羁绊很深，而且承袭D的意志，应该上船吧...</p>
&nbsp;<img src="/imgs/luo.jpg" width="100" height="100"/><img src="/imgs/LAW.png" width="110" height="105"/>
</script>
</object>
</ul>
</div>

  
<div class="widget tag">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/2015/03/02/简明深度学习方法概述（三）/"><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;简明深度学习方法概述（三）</a>
      </li>
    
      <li>
        <a href="/2014/12/07/flask-css不能更新的问题/"><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;flask css不能更新的问题</a>
      </li>
    
      <li>
        <a href="/2014/12/06/简明深度学习方法概述（二）/"><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;简明深度学习方法概述（二）</a>
      </li>
    
      <li>
        <a href="/2014/12/02/简明深度学习方法概述（一）/"><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;简明深度学习方法概述（一）</a>
      </li>
    
      <li>
        <a href="/2014/10/30/程序员与画家/"><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;程序员与画家</a>
      </li>
    
  </ul>
</div>


  <div class="widget tag">
<iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=1&noborder=0&isWeibo=1&isFans=0&uid=3099146883&verifier=3f2fb334&colors=ffffff,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe>
</div>

  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="/categories/DL&ML/">DL&amp;ML</a><small>3</small></li>
  
    <li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="/categories/python/">python</a><small>3</small></li>
  
    <li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="/categories/代码托管/">代码托管</a><small>1</small></li>
  
    <li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="/categories/嵌入式/">嵌入式</a><small>1</small></li>
  
    <li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="/categories/转载/">转载</a><small>1</small></li>
  
    <li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="/categories/随笔/">随笔</a><small>1</small></li>
  
  </ul>
</div>


  <div class="widget tag">
<h3 class="title">友情链接</h3>
<ul class="entry">
<li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="http://coolshell.cn/" title="程浩's blog">酷壳-CoolShell</a></li>
<li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="http://www.foreverpx.cn/" title="潘神">Foreverpx主页</a></li>
<li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="http://taosay.net/index.php/page/2/" title="道哥's blog">道哥的黑板报</a></li>
<li><img src="/imgs/point.png" width="10" height="10"/>&nbsp;&nbsp;<a href="http://www.yinwang.org/" title="王垠's blog">王垠主页</a></li>
</ul>
</div>
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 goldencwcui
  
</div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<script type="text/javascript">
var duoshuoQuery = {short_name:"pangge"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.unstable.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
</body>
</html>